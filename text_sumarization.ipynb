{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text sumarization",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jw3Q5Y-Hl17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('/content/drive/My Drive/Reviews.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SI02b8maKGS1",
        "colab_type": "code",
        "outputId": "6aab19ea-7123-473a-9af0-91ac63d0d774",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(568454, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNIme7dOKxOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=data[:10000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0el0XnIKyL5",
        "colab_type": "code",
        "outputId": "c38cec57-9ca0-4f54-befa-8d1cafe07684",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  ...                                               Text\n",
              "0   1  ...  I have bought several of the Vitality canned d...\n",
              "1   2  ...  Product arrived labeled as Jumbo Salted Peanut...\n",
              "2   3  ...  This is a confection that has been around a fe...\n",
              "3   4  ...  If you are looking for the secret ingredient i...\n",
              "4   5  ...  Great taffy at a great price.  There was a wid...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0w3MSm2OheA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_text = data['Text'].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5261VAwkOunt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_text = data['Summary'].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDxR8P_QOx3d",
        "colab_type": "code",
        "outputId": "67940143-19d1-4ce8-8b32-3f55d41e1510",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(input_text),len(output_text)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGaAaVW6PCMD",
        "colab_type": "text"
      },
      "source": [
        "# PREPROCESSING\n",
        "\n",
        "\n",
        "1.   lowercase\n",
        "2.   removing html tags\n",
        "3.   removing appostrophe\n",
        "4.   's removing\n",
        "5.   removing any text hide in () paranthesis\n",
        "\n",
        "6.   removing punctuation and special characters\n",
        "7.   removing stopwords\n",
        "8.   remove short words \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MZXGGmSO_f-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "\n",
        "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flErusjUPXY7",
        "colab_type": "code",
        "outputId": "89f9271e-44a7-4331-a37c-41d0c1216c2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnvXa6sQQvVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stopwords = set(stopwords.words('english'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43d8KJ4kRA1C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "def text_cleaner(text):\n",
        "  new_text = text.lower()\n",
        "  new_text = BeautifulSoup(new_text,'lxml').text\n",
        "  new_text = re.sub(r'\\([^)]*\\)','',text)\n",
        "  new_text = re.sub('\"','',text)\n",
        "  new_text = ','.join([contraction_mapping[t] if t in contraction_mapping else t for t in new_text.split(\" \")])\n",
        "  new_text = re.sub(r\"'s\\b\",\"\",new_text)\n",
        "  new_text = re.sub(\"[^a-zA-Z]\", \" \", new_text)\n",
        "  tokens = [w for w in new_text.split() if not w in stopwords]\n",
        "  long_words=[]\n",
        "  for i in tokens:\n",
        "      if len(i)>=3:                  #removing short word\n",
        "          long_words.append(i)   \n",
        "  return (\" \".join(long_words)).strip() \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIarbeimRCZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleaned_text = []\n",
        "for text in input_text:\n",
        "  t = text_cleaner(text)\n",
        "  cleaned_text.append(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ml4fobSeTZL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def summary_cleaner(text):\n",
        "    newString = re.sub('\"','', text)\n",
        "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString)\n",
        "    newString = newString.lower()\n",
        "    tokens=newString.split()\n",
        "    newString=''\n",
        "    for i in tokens:\n",
        "        if len(i)>1:                                 \n",
        "            newString=newString+i+' '  \n",
        "    return newString"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0WRPYx1TjCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleaned_output = []\n",
        "for text in output_text:\n",
        "  t = summary_cleaner(text)\n",
        "  cleaned_output.append(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOBatTTBTvMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " import matplotlib.pyplot as plt\n",
        " text_word_count = []\n",
        " summary_word_count = []\n",
        " \n",
        "\n",
        " for i in cleaned_text:\n",
        "   text_word_count.append(len(i.split()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-cz2KT5U5__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in cleaned_output:\n",
        "  summary_word_count.append(len(i.split()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOmIhQXQW9LD",
        "colab_type": "code",
        "outputId": "8c95ac8f-936d-487c-c9bc-10b12a9c0ffe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "source": [
        "length_df = pd.DataFrame({'text':text_word_count,'summary':summary_word_count})\n",
        "length_df.hist(bins=30)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f547d32fa90>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f547c445da0>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aPN57peU8ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_text = []\n",
        "target_input_text =[]\n",
        "for text in cleaned_output:\n",
        "  t1= text + ' <END> '\n",
        "  t2 = '<START> ' + text\n",
        "  target_text.append(t1)\n",
        "  target_input_text.append(t2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPv9e-_KWPn0",
        "colab_type": "code",
        "outputId": "4b5e1c48-a287-4865-e658-61880ab11cc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWs8j8aAXWWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_tokenizer = Tokenizer()\n",
        "text_tokenizer.fit_on_texts(cleaned_text)\n",
        "input_seq = text_tokenizer.texts_to_sequences(cleaned_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7ex8GBYXpWK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "padded_input = pad_sequences(input_seq,padding = 'post',maxlen=80)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05el3bUhYXwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sum_tokenizer=Tokenizer(filters='')\n",
        "sum_tokenizer.fit_on_texts(target_text + target_input_text)\n",
        "target_seq = sum_tokenizer.texts_to_sequences(target_text)\n",
        "target_input_seq = sum_tokenizer.texts_to_sequences(target_input_text)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3sS49wKaq6j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "padded_target = pad_sequences(target_seq,padding='post',maxlen=10)\n",
        "padded_input_target = pad_sequences(target_input_seq,padding='post',maxlen=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPjk2dhybBNh",
        "colab_type": "code",
        "outputId": "ba3a5bc7-802c-4612-d868-5f783d6ef40b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-30 13:14:42--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-03-30 13:14:42--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-03-30 13:14:42--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip.2’\n",
            "\n",
            "\rglove.6B.zip.2        0%[                    ]       0  --.-KB/s               \rglove.6B.zip.2        0%[                    ]   3.51M  17.4MB/s               ^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OZdAZ_Qbkxn",
        "colab_type": "code",
        "outputId": "cd67f389-049b-45d6-9ced-ebd02bd1903f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!unzip glove*.zip"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vI9LKbSRdPGx",
        "colab_type": "code",
        "outputId": "0377e7d1-317b-46c0-e907-35a64db67ade",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('indexing word vectors')\n",
        "import numpy as np\n",
        "embedding_index = {}\n",
        "f = open('/content/glove.6B.300d.txt',encoding='utf-8')\n",
        "for line in f:\n",
        "  values = line.split()\n",
        "  word = values[0]\n",
        "  coeff= np.asarray(values[1:],dtype='float32')\n",
        "  embedding_index[word]=coeff\n",
        "  "
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "indexing word vectors\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsP5opZgeBGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_words_input = len(text_tokenizer.word_index) + 1\n",
        "word2index_input = text_tokenizer.word_index\n",
        "embedding_matrix = np.zeros((num_words_input,300))\n",
        "for word, i in word2index_input.items():\n",
        "  if i < num_words_input:\n",
        "      embedding_vector=embedding_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "      embedding_matrix[i]=embedding_vector\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoPPGiWKe2Nk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Embedding,LSTM,Bidirectional,Input\n",
        "embed_layer =Embedding(num_words_input,300,weights=[embedding_matrix], input_length=80, name ='embedindg_layer')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1N7ljPMfigq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lstm1 = LSTM(300,return_sequences=True, name='lstm1')\n",
        "lstm2=LSTM(300,return_state=True, name = 'lstm_input2')\n",
        "encoder_input = Input(shape=(80,),name='input_layer1')\n",
        "encoder_input1 = embed_layer(encoder_input)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Xw_OkP0gYeZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_output1=lstm1(encoder_input1)\n",
        "encoder_output,state_h,state_c=lstm2(encoder_output1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIuwMz4jgjV0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_states=[state_h,state_c]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogFbwEKKhq7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_output = len(sum_tokenizer.word_index) + 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8tfBQbJhSix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_inputs= Input(shape=(10,), name = 'input_layer2')\n",
        "\n",
        "output_embedding = Embedding(vocab_output,300,input_length=10)\n",
        "decoder_lstm1=LSTM(300,return_sequences = True, name = 'lstm2')\n",
        "decoder_lstm2=LSTM(300,return_sequences=True,return_state=True, name = 'lstm2_output')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOPqmwWrh4Ws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_input1 = output_embedding(decoder_inputs)\n",
        "decoder_output1 = decoder_lstm1(decoder_input1)\n",
        "decoder_output,_,_ = decoder_lstm2(decoder_input1,initial_state=encoder_states)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iDba3dNjMcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import TimeDistributed\n",
        "decoder_dense  = TimeDistributed(Dense(vocab_output, activation = 'softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4JVGToFj2qT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from tensorflow.keras.models import Model\n",
        "model = Model([encoder_input,decoder_inputs],decoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbIzk-yMo3dv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_target_one_hot=np.zeros((len(cleaned_text),10,vocab_output),dtype='float32')\n",
        "for i,d in enumerate(padded_target):\n",
        "    for t, word in enumerate(d):\n",
        "        decoder_target_one_hot[i,t,word]=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLaHTPoCkQSS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP1-VRS7p2xu",
        "colab_type": "code",
        "outputId": "6fdbff37-3d78-454c-c43c-d4751f52a005",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit([padded_input,padded_input_target],decoder_target_one_hot,epochs=100,batch_size=32,validation_split = 0.3)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "219/219 [==============================] - 15s 68ms/step - loss: 2.9007 - accuracy: 0.6061 - val_loss: 2.6705 - val_accuracy: 0.6349\n",
            "Epoch 2/100\n",
            "219/219 [==============================] - 13s 59ms/step - loss: 2.5840 - accuracy: 0.6305 - val_loss: 2.6337 - val_accuracy: 0.6384\n",
            "Epoch 3/100\n",
            "219/219 [==============================] - 13s 60ms/step - loss: 2.5043 - accuracy: 0.6349 - val_loss: 2.5950 - val_accuracy: 0.6426\n",
            "Epoch 4/100\n",
            "219/219 [==============================] - 13s 60ms/step - loss: 2.4309 - accuracy: 0.6399 - val_loss: 2.5775 - val_accuracy: 0.6449\n",
            "Epoch 5/100\n",
            "219/219 [==============================] - 13s 59ms/step - loss: 2.3617 - accuracy: 0.6445 - val_loss: 2.5542 - val_accuracy: 0.6481\n",
            "Epoch 6/100\n",
            "219/219 [==============================] - 13s 60ms/step - loss: 2.2986 - accuracy: 0.6496 - val_loss: 2.5278 - val_accuracy: 0.6517\n",
            "Epoch 7/100\n",
            "219/219 [==============================] - 13s 58ms/step - loss: 2.2391 - accuracy: 0.6541 - val_loss: 2.5244 - val_accuracy: 0.6509\n",
            "Epoch 8/100\n",
            "219/219 [==============================] - 13s 60ms/step - loss: 2.1805 - accuracy: 0.6598 - val_loss: 2.5157 - val_accuracy: 0.6546\n",
            "Epoch 9/100\n",
            "219/219 [==============================] - 13s 59ms/step - loss: 2.1261 - accuracy: 0.6652 - val_loss: 2.5190 - val_accuracy: 0.6542\n",
            "Epoch 10/100\n",
            "219/219 [==============================] - 13s 59ms/step - loss: 2.0717 - accuracy: 0.6702 - val_loss: 2.5109 - val_accuracy: 0.6548\n",
            "Epoch 11/100\n",
            "219/219 [==============================] - 13s 59ms/step - loss: 2.0166 - accuracy: 0.6760 - val_loss: 2.5218 - val_accuracy: 0.6549\n",
            "Epoch 12/100\n",
            "219/219 [==============================] - 13s 58ms/step - loss: 1.9627 - accuracy: 0.6820 - val_loss: 2.5372 - val_accuracy: 0.6507\n",
            "Epoch 13/100\n",
            "219/219 [==============================] - 13s 59ms/step - loss: 1.9078 - accuracy: 0.6878 - val_loss: 2.5520 - val_accuracy: 0.6524\n",
            "Epoch 14/100\n",
            "219/219 [==============================] - 13s 59ms/step - loss: 1.8518 - accuracy: 0.6940 - val_loss: 2.5699 - val_accuracy: 0.6483\n",
            "Epoch 15/100\n",
            "219/219 [==============================] - 13s 61ms/step - loss: 1.7939 - accuracy: 0.6999 - val_loss: 2.5937 - val_accuracy: 0.6486\n",
            "Epoch 16/100\n",
            "219/219 [==============================] - 13s 59ms/step - loss: 1.7377 - accuracy: 0.7062 - val_loss: 2.6274 - val_accuracy: 0.6433\n",
            "Epoch 17/100\n",
            "219/219 [==============================] - 13s 60ms/step - loss: 1.6816 - accuracy: 0.7131 - val_loss: 2.6582 - val_accuracy: 0.6422\n",
            "Epoch 18/100\n",
            "219/219 [==============================] - 13s 59ms/step - loss: 1.6263 - accuracy: 0.7207 - val_loss: 2.6729 - val_accuracy: 0.6445\n",
            "Epoch 19/100\n",
            "219/219 [==============================] - 13s 59ms/step - loss: 1.5695 - accuracy: 0.7293 - val_loss: 2.7162 - val_accuracy: 0.6393\n",
            "Epoch 20/100\n",
            "219/219 [==============================] - 13s 59ms/step - loss: 1.5169 - accuracy: 0.7381 - val_loss: 2.7355 - val_accuracy: 0.6409\n",
            "Epoch 21/100\n",
            "219/219 [==============================] - 13s 59ms/step - loss: 1.4592 - accuracy: 0.7467 - val_loss: 2.7683 - val_accuracy: 0.6438\n",
            "Epoch 22/100\n",
            "219/219 [==============================] - 13s 59ms/step - loss: 1.4039 - accuracy: 0.7538 - val_loss: 2.8034 - val_accuracy: 0.6390\n",
            "Epoch 23/100\n",
            "219/219 [==============================] - 13s 60ms/step - loss: 1.3500 - accuracy: 0.7638 - val_loss: 2.8287 - val_accuracy: 0.6384\n",
            "Epoch 24/100\n",
            "219/219 [==============================] - 13s 60ms/step - loss: 1.2977 - accuracy: 0.7722 - val_loss: 2.8666 - val_accuracy: 0.6348\n",
            "Epoch 25/100\n",
            "219/219 [==============================] - 13s 59ms/step - loss: 1.2475 - accuracy: 0.7829 - val_loss: 2.8975 - val_accuracy: 0.6341\n",
            "Epoch 26/100\n",
            "219/219 [==============================] - 13s 60ms/step - loss: 1.1975 - accuracy: 0.7911 - val_loss: 2.9214 - val_accuracy: 0.6355\n",
            "Epoch 27/100\n",
            "219/219 [==============================] - 13s 59ms/step - loss: 1.1492 - accuracy: 0.8009 - val_loss: 2.9717 - val_accuracy: 0.6345\n",
            "Epoch 28/100\n",
            "219/219 [==============================] - 13s 60ms/step - loss: 1.1055 - accuracy: 0.8090 - val_loss: 3.0052 - val_accuracy: 0.6313\n",
            "Epoch 29/100\n",
            "219/219 [==============================] - 13s 59ms/step - loss: 1.0584 - accuracy: 0.8181 - val_loss: 3.0537 - val_accuracy: 0.6232\n",
            "Epoch 30/100\n",
            "219/219 [==============================] - 13s 59ms/step - loss: 1.0149 - accuracy: 0.8265 - val_loss: 3.0772 - val_accuracy: 0.6302\n",
            "Epoch 31/100\n",
            "219/219 [==============================] - 13s 59ms/step - loss: 0.9744 - accuracy: 0.8342 - val_loss: 3.0925 - val_accuracy: 0.6277\n",
            "Epoch 32/100\n",
            "219/219 [==============================] - 13s 59ms/step - loss: 0.9322 - accuracy: 0.8425 - val_loss: 3.1184 - val_accuracy: 0.6279\n",
            "Epoch 33/100\n",
            "219/219 [==============================] - 13s 59ms/step - loss: 0.8934 - accuracy: 0.8489 - val_loss: 3.1437 - val_accuracy: 0.6296\n",
            "Epoch 34/100\n",
            "219/219 [==============================] - 13s 60ms/step - loss: 0.8562 - accuracy: 0.8566 - val_loss: 3.1840 - val_accuracy: 0.6239\n",
            "Epoch 35/100\n",
            "219/219 [==============================] - 13s 60ms/step - loss: 0.8195 - accuracy: 0.8635 - val_loss: 3.1830 - val_accuracy: 0.6260\n",
            "Epoch 36/100\n",
            "219/219 [==============================] - 13s 61ms/step - loss: 0.7835 - accuracy: 0.8714 - val_loss: 3.2184 - val_accuracy: 0.6242\n",
            "Epoch 37/100\n",
            "219/219 [==============================] - 13s 59ms/step - loss: 0.7536 - accuracy: 0.8771 - val_loss: 3.2539 - val_accuracy: 0.6232\n",
            "Epoch 38/100\n",
            "219/219 [==============================] - 13s 59ms/step - loss: 0.7235 - accuracy: 0.8823 - val_loss: 3.2902 - val_accuracy: 0.6219\n",
            "Epoch 39/100\n",
            "219/219 [==============================] - 13s 60ms/step - loss: 0.6894 - accuracy: 0.8887 - val_loss: 3.2897 - val_accuracy: 0.6238\n",
            "Epoch 40/100\n",
            "219/219 [==============================] - 13s 59ms/step - loss: 0.6623 - accuracy: 0.8946 - val_loss: 3.3169 - val_accuracy: 0.6229\n",
            "Epoch 41/100\n",
            "219/219 [==============================] - 13s 60ms/step - loss: 0.6322 - accuracy: 0.8993 - val_loss: 3.3569 - val_accuracy: 0.6191\n",
            "Epoch 42/100\n",
            "219/219 [==============================] - 13s 60ms/step - loss: 0.6069 - accuracy: 0.9039 - val_loss: 3.3465 - val_accuracy: 0.6229\n",
            "Epoch 43/100\n",
            "176/219 [=======================>......] - ETA: 2s - loss: 0.5684 - accuracy: 0.9119"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-ed7718b541e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpadded_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadded_input_target\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_target_one_hot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    781\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    782\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxkQFaA6qMjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_model =Model(encoder_input,encoder_states)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JT48OPpb96w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_state_input_h = Input(shape=(100,))\n",
        "decoder_state_input_c= Input(shape=(100,))\n",
        "decoder_state_input = [decoder_state_input_h,decoder_state_input_c]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xag9RH7cWnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_input_single = Input(shape=(1,))\n",
        "decoder_input_single_x = output_embedding(decoder_input_single)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7o5V5d6dGs_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_output,h,c=decoder_lstm(decoder_input_single_x,initial_state=decoder_state_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4K0IUQ_wdiNM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_states = [h,c]\n",
        "decoder_model =Model([decoder_input_single]+decoder_state_input,[decoder_output]+decoder_states)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIa1nTjre9tf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2index_input = text_tokenizer.word_index\n",
        "word2index_output = sum_tokenizer.word_index\n",
        "idx2word_text = {v:k for k,v in word2index_input.items()}\n",
        "idx2word_sum = {v:k for k,v in word2index_output.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UU0ueV8o_X-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9fe43097-db50-444a-9e05-efcb805ab4fe"
      },
      "source": [
        "word2index_output\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<end>': 1,\n",
              " '<start>': 2,\n",
              " 'great': 3,\n",
              " 'good': 4,\n",
              " 'the': 5,\n",
              " 'not': 6,\n",
              " 'for': 7,\n",
              " 'best': 8,\n",
              " 'and': 9,\n",
              " 'coffee': 10,\n",
              " 'it': 11,\n",
              " 'my': 12,\n",
              " 'but': 13,\n",
              " 'love': 14,\n",
              " 'of': 15,\n",
              " 'is': 16,\n",
              " 'to': 17,\n",
              " 'this': 18,\n",
              " 'product': 19,\n",
              " 'taste': 20,\n",
              " 'delicious': 21,\n",
              " 'very': 22,\n",
              " 'in': 23,\n",
              " 'flavor': 24,\n",
              " 'tea': 25,\n",
              " 'food': 26,\n",
              " 'excellent': 27,\n",
              " 'yummy': 28,\n",
              " 'like': 29,\n",
              " 'tasty': 30,\n",
              " 'dog': 31,\n",
              " 'you': 32,\n",
              " 'too': 33,\n",
              " 'favorite': 34,\n",
              " 'as': 35,\n",
              " 'price': 36,\n",
              " 'chips': 37,\n",
              " 'these': 38,\n",
              " 'ever': 39,\n",
              " 'so': 40,\n",
              " 'with': 41,\n",
              " 'hot': 42,\n",
              " 'are': 43,\n",
              " 'cup': 44,\n",
              " 'just': 45,\n",
              " 'have': 46,\n",
              " 'on': 47,\n",
              " 'better': 48,\n",
              " 'free': 49,\n",
              " 'stuff': 50,\n",
              " 'chocolate': 51,\n",
              " 'no': 52,\n",
              " 'sweet': 53,\n",
              " 'perfect': 54,\n",
              " 'what': 55,\n",
              " 'healthy': 56,\n",
              " 'nice': 57,\n",
              " 'awesome': 58,\n",
              " 'loves': 59,\n",
              " 'me': 60,\n",
              " 'yum': 61,\n",
              " 'one': 62,\n",
              " 'bad': 63,\n",
              " 'quality': 64,\n",
              " 'snack': 65,\n",
              " 'mix': 66,\n",
              " 'really': 67,\n",
              " 'than': 68,\n",
              " 'tasting': 69,\n",
              " 'wonderful': 70,\n",
              " 'cups': 71,\n",
              " 'all': 72,\n",
              " 'tastes': 73,\n",
              " 'gluten': 74,\n",
              " 'cocoa': 75,\n",
              " 'at': 76,\n",
              " 'can': 77,\n",
              " 'be': 78,\n",
              " 'much': 79,\n",
              " 'your': 80,\n",
              " 'from': 81,\n",
              " 'little': 82,\n",
              " 'easy': 83,\n",
              " 'buy': 84,\n",
              " 'cat': 85,\n",
              " 'them': 86,\n",
              " 'do': 87,\n",
              " 'dogs': 88,\n",
              " 'organic': 89,\n",
              " 'cats': 90,\n",
              " 'that': 91,\n",
              " 'ok': 92,\n",
              " 'sugar': 93,\n",
              " 'drink': 94,\n",
              " 'will': 95,\n",
              " 'if': 96,\n",
              " 'treat': 97,\n",
              " 'baby': 98,\n",
              " 'an': 99,\n",
              " 'more': 100,\n",
              " 'pretty': 101,\n",
              " 'they': 102,\n",
              " 'amazing': 103,\n",
              " 'decaf': 104,\n",
              " 'was': 105,\n",
              " 'treats': 106,\n",
              " 'soda': 107,\n",
              " 'way': 108,\n",
              " 'fresh': 109,\n",
              " 'smooth': 110,\n",
              " 'alternative': 111,\n",
              " 'puck': 112,\n",
              " 'out': 113,\n",
              " 'works': 114,\n",
              " 'wolfgang': 115,\n",
              " 'value': 116,\n",
              " 'water': 117,\n",
              " 'up': 118,\n",
              " 'our': 119,\n",
              " 'popcorn': 120,\n",
              " 'breakfast': 121,\n",
              " 'low': 122,\n",
              " 'real': 123,\n",
              " 'find': 124,\n",
              " 'sauce': 125,\n",
              " 'fantastic': 126,\n",
              " 'amazon': 127,\n",
              " 'or': 128,\n",
              " 'cookies': 129,\n",
              " 'juice': 130,\n",
              " 'hard': 131,\n",
              " 'milk': 132,\n",
              " 'expensive': 133,\n",
              " 'makes': 134,\n",
              " 'does': 135,\n",
              " 'beans': 136,\n",
              " 'flavored': 137,\n",
              " 'use': 138,\n",
              " 'vanilla': 139,\n",
              " 'pancakes': 140,\n",
              " 'natural': 141,\n",
              " 'deal': 142,\n",
              " 'only': 143,\n",
              " 'make': 144,\n",
              " 'pop': 145,\n",
              " 'strong': 146,\n",
              " 'eat': 147,\n",
              " 'new': 148,\n",
              " 'happy': 149,\n",
              " 'get': 150,\n",
              " 'gift': 151,\n",
              " 'had': 152,\n",
              " 'some': 153,\n",
              " 'roast': 154,\n",
              " 'okay': 155,\n",
              " 'coconut': 156,\n",
              " 'keurig': 157,\n",
              " 'other': 158,\n",
              " 'small': 159,\n",
              " 'money': 160,\n",
              " 'again': 161,\n",
              " 'there': 162,\n",
              " 'orange': 163,\n",
              " 'go': 164,\n",
              " 'far': 165,\n",
              " 'light': 166,\n",
              " 'by': 167,\n",
              " 'disappointed': 168,\n",
              " 'work': 169,\n",
              " 'we': 170,\n",
              " 'nothing': 171,\n",
              " 'high': 172,\n",
              " 'decent': 173,\n",
              " 'would': 174,\n",
              " 'green': 175,\n",
              " 'right': 176,\n",
              " 'energy': 177,\n",
              " 'did': 178,\n",
              " 'bit': 179,\n",
              " 'service': 180,\n",
              " 'rich': 181,\n",
              " 'blend': 182,\n",
              " 'weak': 183,\n",
              " 'made': 184,\n",
              " 'bisquick': 185,\n",
              " 'candy': 186,\n",
              " 'salt': 187,\n",
              " 'chip': 188,\n",
              " 'well': 189,\n",
              " 'gum': 190,\n",
              " 'don': 191,\n",
              " 'bitter': 192,\n",
              " 'bread': 193,\n",
              " 'refreshing': 194,\n",
              " 'convenient': 195,\n",
              " 'spicy': 196,\n",
              " 'licorice': 197,\n",
              " 'white': 198,\n",
              " 'wow': 199,\n",
              " 'expected': 200,\n",
              " 'am': 201,\n",
              " 'worth': 202,\n",
              " 'poor': 203,\n",
              " 'item': 204,\n",
              " 'review': 205,\n",
              " 'awful': 206,\n",
              " 'oil': 207,\n",
              " 'baking': 208,\n",
              " 'popchips': 209,\n",
              " 'seeds': 210,\n",
              " 'instant': 211,\n",
              " 'fruit': 212,\n",
              " 'packaging': 213,\n",
              " 'could': 214,\n",
              " 'absolutely': 215,\n",
              " 'hazelnut': 216,\n",
              " 'time': 217,\n",
              " 'variety': 218,\n",
              " 'mild': 219,\n",
              " 'enough': 220,\n",
              " 'without': 221,\n",
              " 'flavors': 222,\n",
              " 'first': 223,\n",
              " 'fun': 224,\n",
              " 'old': 225,\n",
              " 'how': 226,\n",
              " 'calorie': 227,\n",
              " 'soup': 228,\n",
              " 'worst': 229,\n",
              " 'horrible': 230,\n",
              " 'dark': 231,\n",
              " 'special': 232,\n",
              " 'rice': 233,\n",
              " 'never': 234,\n",
              " 'shipping': 235,\n",
              " 'potato': 236,\n",
              " 'got': 237,\n",
              " 'flavorful': 238,\n",
              " 'disposakups': 239,\n",
              " 'pack': 240,\n",
              " 'kids': 241,\n",
              " 'loved': 242,\n",
              " 'terrible': 243,\n",
              " 'tasted': 244,\n",
              " 'french': 245,\n",
              " 'still': 246,\n",
              " 'diet': 247,\n",
              " 'why': 248,\n",
              " 'super': 249,\n",
              " 'about': 250,\n",
              " 'salty': 251,\n",
              " 'quick': 252,\n",
              " 'choice': 253,\n",
              " 'crazy': 254,\n",
              " 'jerky': 255,\n",
              " 'bed': 256,\n",
              " 'medium': 257,\n",
              " 'order': 258,\n",
              " 'over': 259,\n",
              " 'has': 260,\n",
              " 'disappointing': 261,\n",
              " 'size': 262,\n",
              " 'almost': 263,\n",
              " 'different': 264,\n",
              " 'now': 265,\n",
              " 'even': 266,\n",
              " 'substitute': 267,\n",
              " 'switch': 268,\n",
              " 'bag': 269,\n",
              " 'big': 270,\n",
              " 'fast': 271,\n",
              " 'fan': 272,\n",
              " 'kettle': 273,\n",
              " 'were': 274,\n",
              " 'own': 275,\n",
              " 'corn': 276,\n",
              " 'powder': 277,\n",
              " 'gf': 278,\n",
              " 'day': 279,\n",
              " 'brew': 280,\n",
              " 'wrong': 281,\n",
              " 'simply': 282,\n",
              " 'waste': 283,\n",
              " 'beware': 284,\n",
              " 'most': 285,\n",
              " 'pancake': 286,\n",
              " 'after': 287,\n",
              " 'formula': 288,\n",
              " 'whole': 289,\n",
              " 'another': 290,\n",
              " 'oz': 291,\n",
              " 'yet': 292,\n",
              " 'found': 293,\n",
              " 'full': 294,\n",
              " 'pods': 295,\n",
              " 'surprisingly': 296,\n",
              " 'bold': 297,\n",
              " 'regular': 298,\n",
              " 'stale': 299,\n",
              " 'life': 300,\n",
              " 'something': 301,\n",
              " 'pricey': 302,\n",
              " 'brand': 303,\n",
              " 'goodness': 304,\n",
              " 'its': 305,\n",
              " 'crackers': 306,\n",
              " 'oatmeal': 307,\n",
              " 'those': 308,\n",
              " 'vinegar': 309,\n",
              " 'idea': 310,\n",
              " 'fat': 311,\n",
              " 'store': 312,\n",
              " 'ingredients': 313,\n",
              " 'chicken': 314,\n",
              " 'crunchy': 315,\n",
              " 'want': 316,\n",
              " 'down': 317,\n",
              " 'soy': 318,\n",
              " 'cereal': 319,\n",
              " 'tried': 320,\n",
              " 'yuck': 321,\n",
              " 'customer': 322,\n",
              " 'cake': 323,\n",
              " 'lot': 324,\n",
              " 'senseo': 325,\n",
              " 'carbonated': 326,\n",
              " 'lots': 327,\n",
              " 'nuts': 328,\n",
              " 'every': 329,\n",
              " 'soft': 330,\n",
              " 'honey': 331,\n",
              " 'spice': 332,\n",
              " 'true': 333,\n",
              " 'available': 334,\n",
              " 'earth': 335,\n",
              " 'espresso': 336,\n",
              " 'canned': 337,\n",
              " 'try': 338,\n",
              " 'name': 339,\n",
              " 'beef': 340,\n",
              " 'butter': 341,\n",
              " 'goat': 342,\n",
              " 'grass': 343,\n",
              " 'disposable': 344,\n",
              " 'always': 345,\n",
              " 'lovers': 346,\n",
              " 'who': 347,\n",
              " 'miracle': 348,\n",
              " 'unique': 349,\n",
              " 'cost': 350,\n",
              " 'thing': 351,\n",
              " 'should': 352,\n",
              " 'stars': 353,\n",
              " 'caramel': 354,\n",
              " 'syrup': 355,\n",
              " 'bland': 356,\n",
              " 'outstanding': 357,\n",
              " 'non': 358,\n",
              " 'family': 359,\n",
              " 'sticks': 360,\n",
              " 'picky': 361,\n",
              " 'likes': 362,\n",
              " 'bought': 363,\n",
              " 'must': 364,\n",
              " 'didn': 365,\n",
              " 'less': 366,\n",
              " 'texture': 367,\n",
              " 'cracker': 368,\n",
              " 'grove': 369,\n",
              " 'tangerine': 370,\n",
              " 'nasty': 371,\n",
              " 'cookie': 372,\n",
              " 'last': 373,\n",
              " 'cannot': 374,\n",
              " 'fabulous': 375,\n",
              " 'sure': 376,\n",
              " 'highly': 377,\n",
              " 'around': 378,\n",
              " 'quite': 379,\n",
              " 'aftertaste': 380,\n",
              " 'addictive': 381,\n",
              " 'crunch': 382,\n",
              " 'needs': 383,\n",
              " 'when': 384,\n",
              " 'red': 385,\n",
              " 'where': 386,\n",
              " 'any': 387,\n",
              " 'heaven': 388,\n",
              " 'son': 389,\n",
              " 'calories': 390,\n",
              " 'smells': 391,\n",
              " 'snacks': 392,\n",
              " 'say': 393,\n",
              " 'ordered': 394,\n",
              " 'back': 395,\n",
              " 'beautiful': 396,\n",
              " 'off': 397,\n",
              " 'priced': 398,\n",
              " 'aroma': 399,\n",
              " 'finally': 400,\n",
              " 'cheese': 401,\n",
              " 'used': 402,\n",
              " 'been': 403,\n",
              " 'misleading': 404,\n",
              " 'batch': 405,\n",
              " 'overpriced': 406,\n",
              " 'dessert': 407,\n",
              " 'favorites': 408,\n",
              " 'gravy': 409,\n",
              " 'totally': 410,\n",
              " 'packaged': 411,\n",
              " 'iced': 412,\n",
              " 'muffins': 413,\n",
              " 'wish': 414,\n",
              " 'cans': 415,\n",
              " 'products': 416,\n",
              " 'pleased': 417,\n",
              " 'square': 418,\n",
              " 'plant': 419,\n",
              " 'newman': 420,\n",
              " 'delight': 421,\n",
              " 'home': 422,\n",
              " 'same': 423,\n",
              " 'us': 424,\n",
              " 'english': 425,\n",
              " 'bite': 426,\n",
              " 'broken': 427,\n",
              " 'mini': 428,\n",
              " 'average': 429,\n",
              " 'recommended': 430,\n",
              " 'bbq': 431,\n",
              " 'oh': 432,\n",
              " 'smell': 433,\n",
              " 'know': 434,\n",
              " 'crispy': 435,\n",
              " 'need': 436,\n",
              " 'delivery': 437,\n",
              " 'disappointment': 438,\n",
              " 'though': 439,\n",
              " 'house': 440,\n",
              " 'interesting': 441,\n",
              " 'open': 442,\n",
              " 'reviews': 443,\n",
              " 'pasta': 444,\n",
              " 'mmm': 445,\n",
              " 'healthier': 446,\n",
              " 'waffles': 447,\n",
              " 'summer': 448,\n",
              " 'think': 449,\n",
              " 'ground': 450,\n",
              " 'their': 451,\n",
              " 'please': 452,\n",
              " 'satisfying': 453,\n",
              " 'here': 454,\n",
              " 'cheaper': 455,\n",
              " 'worked': 456,\n",
              " 'flour': 457,\n",
              " 'health': 458,\n",
              " 'artificial': 459,\n",
              " 'impressed': 460,\n",
              " 'bar': 461,\n",
              " 'wild': 462,\n",
              " 'bags': 463,\n",
              " 'tangy': 464,\n",
              " 'box': 465,\n",
              " 'lover': 466,\n",
              " 'black': 467,\n",
              " 'helps': 468,\n",
              " 'cheap': 469,\n",
              " 'fine': 470,\n",
              " 'bars': 471,\n",
              " 'protein': 472,\n",
              " 'thin': 473,\n",
              " 'delish': 474,\n",
              " 'dressing': 475,\n",
              " 'cherry': 476,\n",
              " 'peanut': 477,\n",
              " 'china': 478,\n",
              " 'thought': 479,\n",
              " 'two': 480,\n",
              " 'purchase': 481,\n",
              " 'option': 482,\n",
              " 'waffle': 483,\n",
              " 'mustard': 484,\n",
              " 'beverage': 485,\n",
              " 'clam': 486,\n",
              " 'world': 487,\n",
              " 'simple': 488,\n",
              " 'bean': 489,\n",
              " 'arrived': 490,\n",
              " 'em': 491,\n",
              " 'looking': 492,\n",
              " 'loose': 493,\n",
              " 'raw': 494,\n",
              " 'seasoning': 495,\n",
              " 'exactly': 496,\n",
              " 'surprise': 497,\n",
              " 'brown': 498,\n",
              " 'maybe': 499,\n",
              " 'extra': 500,\n",
              " 'gourmet': 501,\n",
              " 're': 502,\n",
              " 'addicted': 503,\n",
              " 'close': 504,\n",
              " 'things': 505,\n",
              " 'meh': 506,\n",
              " 'cute': 507,\n",
              " 'weight': 508,\n",
              " 'aluminum': 509,\n",
              " 'everything': 510,\n",
              " 'watery': 511,\n",
              " 'received': 512,\n",
              " 'dry': 513,\n",
              " 'slightly': 514,\n",
              " 'meal': 515,\n",
              " 'premium': 516,\n",
              " 'many': 517,\n",
              " 'mill': 518,\n",
              " 'acidic': 519,\n",
              " 'jamaica': 520,\n",
              " 'chia': 521,\n",
              " 'advertised': 522,\n",
              " 'nutrition': 523,\n",
              " 'hit': 524,\n",
              " 'foods': 525,\n",
              " 'eating': 526,\n",
              " 'olive': 527,\n",
              " 'thai': 528,\n",
              " 'crisp': 529,\n",
              " 'miss': 530,\n",
              " 'buying': 531,\n",
              " 'sodium': 532,\n",
              " 'date': 533,\n",
              " 'dont': 534,\n",
              " 'sweetener': 535,\n",
              " 'tortilla': 536,\n",
              " 'liked': 537,\n",
              " 'others': 538,\n",
              " 'lovely': 539,\n",
              " 'contains': 540,\n",
              " 'kitty': 541,\n",
              " 'long': 542,\n",
              " 'into': 543,\n",
              " 'solution': 544,\n",
              " 'stevia': 545,\n",
              " 'inexpensive': 546,\n",
              " 'everyone': 547,\n",
              " 'top': 548,\n",
              " 'away': 549,\n",
              " 'market': 550,\n",
              " 'cool': 551,\n",
              " 'awsome': 552,\n",
              " 'tart': 553,\n",
              " 'cold': 554,\n",
              " 'problems': 555,\n",
              " 'allergy': 556,\n",
              " 'star': 557,\n",
              " 'clean': 558,\n",
              " 'salsa': 559,\n",
              " 'greatest': 560,\n",
              " 'days': 561,\n",
              " 'gave': 562,\n",
              " 'omg': 563,\n",
              " 'keeps': 564,\n",
              " 'anywhere': 565,\n",
              " 'scrumptious': 566,\n",
              " 'look': 567,\n",
              " 'baked': 568,\n",
              " 'onion': 569,\n",
              " 'thick': 570,\n",
              " 'dairy': 571,\n",
              " 'creamy': 572,\n",
              " 'smaller': 573,\n",
              " 'grow': 574,\n",
              " 'instead': 575,\n",
              " 'wanted': 576,\n",
              " 'berry': 577,\n",
              " 'jars': 578,\n",
              " 'daughter': 579,\n",
              " 'leaf': 580,\n",
              " 'people': 581,\n",
              " 'salad': 582,\n",
              " 'yuk': 583,\n",
              " 'enjoyable': 584,\n",
              " 'mouth': 585,\n",
              " 'difference': 586,\n",
              " 'ounce': 587,\n",
              " 'year': 588,\n",
              " 'pepper': 589,\n",
              " 'care': 590,\n",
              " 'crisps': 591,\n",
              " 'enjoy': 592,\n",
              " 'plain': 593,\n",
              " 'cooking': 594,\n",
              " 'original': 595,\n",
              " 'add': 596,\n",
              " 'extremely': 597,\n",
              " 'kcup': 598,\n",
              " 'chowder': 599,\n",
              " 'agree': 600,\n",
              " 'bpa': 601,\n",
              " 'dr': 602,\n",
              " 'tofu': 603,\n",
              " 'then': 604,\n",
              " 'sensitive': 605,\n",
              " 'looks': 606,\n",
              " 'saver': 607,\n",
              " 'help': 608,\n",
              " 'huge': 609,\n",
              " 'changed': 610,\n",
              " 'thanks': 611,\n",
              " 'daily': 612,\n",
              " 'getting': 613,\n",
              " 'yes': 614,\n",
              " 'ice': 615,\n",
              " 'wine': 616,\n",
              " 'grain': 617,\n",
              " 'lightly': 618,\n",
              " 'sour': 619,\n",
              " 'happened': 620,\n",
              " 'recipe': 621,\n",
              " 'creme': 622,\n",
              " 'country': 623,\n",
              " 'chili': 624,\n",
              " 'edible': 625,\n",
              " 'making': 626,\n",
              " 'version': 627,\n",
              " 'dinner': 628,\n",
              " 'stores': 629,\n",
              " 'mint': 630,\n",
              " 'actually': 631,\n",
              " 'garlic': 632,\n",
              " 'training': 633,\n",
              " 'beer': 634,\n",
              " 'hint': 635,\n",
              " 'experience': 636,\n",
              " 'extract': 637,\n",
              " 'pizza': 638,\n",
              " 'company': 639,\n",
              " 'serve': 640,\n",
              " 'eh': 641,\n",
              " 'rock': 642,\n",
              " 'terrific': 643,\n",
              " 'save': 644,\n",
              " 'pineapple': 645,\n",
              " 'brewers': 646,\n",
              " 'feel': 647,\n",
              " 'caribou': 648,\n",
              " 'goes': 649,\n",
              " 'coffees': 650,\n",
              " 'oreo': 651,\n",
              " 'effective': 652,\n",
              " 'toddler': 653,\n",
              " 'hate': 654,\n",
              " 'morning': 655,\n",
              " 'versatile': 656,\n",
              " 'fruity': 657,\n",
              " 'yuban': 658,\n",
              " 'rodeo': 659,\n",
              " 'drive': 660,\n",
              " 'brands': 661,\n",
              " 'came': 662,\n",
              " 'rocks': 663,\n",
              " 'warning': 664,\n",
              " 'lamb': 665,\n",
              " 'allergies': 666,\n",
              " 'mmmmm': 667,\n",
              " 'tasteless': 668,\n",
              " 'banana': 669,\n",
              " 'lemon': 670,\n",
              " 'handy': 671,\n",
              " 'give': 672,\n",
              " 'jelly': 673,\n",
              " 'belly': 674,\n",
              " 'anytime': 675,\n",
              " 'shipped': 676,\n",
              " 'winner': 677,\n",
              " 'base': 678,\n",
              " 'msg': 679,\n",
              " 'read': 680,\n",
              " 'single': 681,\n",
              " 'glad': 682,\n",
              " 'leaves': 683,\n",
              " 'touch': 684,\n",
              " 'disgusting': 685,\n",
              " 'added': 686,\n",
              " 'damaged': 687,\n",
              " 'believe': 688,\n",
              " 'earl': 689,\n",
              " 'grey': 690,\n",
              " 'sweetner': 691,\n",
              " 'wheat': 692,\n",
              " 'amazingly': 693,\n",
              " 'seems': 694,\n",
              " 'liquor': 695,\n",
              " 'odd': 696,\n",
              " 'ones': 697,\n",
              " 'plastic': 698,\n",
              " 'issues': 699,\n",
              " 'pick': 700,\n",
              " 'heat': 701,\n",
              " 'sooo': 702,\n",
              " 'pound': 703,\n",
              " 'false': 704,\n",
              " 'authentic': 705,\n",
              " 'friend': 706,\n",
              " 'nut': 707,\n",
              " 'superb': 708,\n",
              " 'sorry': 709,\n",
              " 'safe': 710,\n",
              " 'longer': 711,\n",
              " 'com': 712,\n",
              " 'babies': 713,\n",
              " 'boxes': 714,\n",
              " 'ginger': 715,\n",
              " 'guilt': 716,\n",
              " 'weird': 717,\n",
              " 'disapointed': 718,\n",
              " 'sunflower': 719,\n",
              " 'surprised': 720,\n",
              " 'dented': 721,\n",
              " 'keep': 722,\n",
              " 'fave': 723,\n",
              " 'definitely': 724,\n",
              " 'teeth': 725,\n",
              " 'key': 726,\n",
              " 'change': 727,\n",
              " 'coco': 728,\n",
              " 'chocolates': 729,\n",
              " 'homemade': 730,\n",
              " 'mixed': 731,\n",
              " 'man': 732,\n",
              " 'problem': 733,\n",
              " 'unremarkable': 734,\n",
              " 'organics': 735,\n",
              " 'sinus': 736,\n",
              " 'lids': 737,\n",
              " 'lime': 738,\n",
              " 'filters': 739,\n",
              " 'grandpa': 740,\n",
              " 'po': 741,\n",
              " 'columbian': 742,\n",
              " 'says': 743,\n",
              " 'fans': 744,\n",
              " 'delivered': 745,\n",
              " 'machine': 746,\n",
              " 'start': 747,\n",
              " 'wife': 748,\n",
              " 'mushy': 749,\n",
              " 'carb': 750,\n",
              " 'balance': 751,\n",
              " 'stomach': 752,\n",
              " 'sea': 753,\n",
              " 'forever': 754,\n",
              " 'mellow': 755,\n",
              " 'half': 756,\n",
              " 'lunch': 757,\n",
              " 'sick': 758,\n",
              " 'fragrant': 759,\n",
              " 'puppy': 760,\n",
              " 'boost': 761,\n",
              " 'barely': 762,\n",
              " 'once': 763,\n",
              " 'line': 764,\n",
              " 'else': 765,\n",
              " 'husband': 766,\n",
              " 'pieces': 767,\n",
              " 'control': 768,\n",
              " 'cream': 769,\n",
              " 'beat': 770,\n",
              " 'prefer': 771,\n",
              " 'gone': 772,\n",
              " 'packs': 773,\n",
              " 'standard': 774,\n",
              " 'tummy': 775,\n",
              " 'using': 776,\n",
              " 'kind': 777,\n",
              " 'kitchen': 778,\n",
              " 'pops': 779,\n",
              " 'gets': 780,\n",
              " 'rating': 781,\n",
              " 'both': 782,\n",
              " 'kona': 783,\n",
              " 'twice': 784,\n",
              " 'heavenly': 785,\n",
              " 'basket': 786,\n",
              " 'party': 787,\n",
              " 'bubble': 788,\n",
              " 'mediocre': 789,\n",
              " 'second': 790,\n",
              " 'local': 791,\n",
              " 'diets': 792,\n",
              " 'easily': 793,\n",
              " 'runny': 794,\n",
              " 'vitamin': 795,\n",
              " 'thumbs': 796,\n",
              " 'nd': 797,\n",
              " 'compared': 798,\n",
              " 'ate': 799,\n",
              " 'paste': 800,\n",
              " 'described': 801,\n",
              " 'may': 802,\n",
              " 'hands': 803,\n",
              " 'addicting': 804,\n",
              " 'picture': 805,\n",
              " 'ingredient': 806,\n",
              " 'custard': 807,\n",
              " 'bacon': 808,\n",
              " 'tree': 809,\n",
              " 'pleasing': 810,\n",
              " 'almond': 811,\n",
              " 'darn': 812,\n",
              " 'live': 813,\n",
              " 'vegan': 814,\n",
              " 'tell': 815,\n",
              " 'acid': 816,\n",
              " 'italian': 817,\n",
              " 'curry': 818,\n",
              " 'lacks': 819,\n",
              " 'except': 820,\n",
              " 'watch': 821,\n",
              " 'amount': 822,\n",
              " 'least': 823,\n",
              " 'eater': 824,\n",
              " 'dirty': 825,\n",
              " 'delightful': 826,\n",
              " 'teas': 827,\n",
              " 'come': 828,\n",
              " 'satisfied': 829,\n",
              " 'recommend': 830,\n",
              " 'dishes': 831,\n",
              " 'pure': 832,\n",
              " 'either': 833,\n",
              " 'replacement': 834,\n",
              " 'mahogany': 835,\n",
              " 'mrs': 836,\n",
              " 'pumpkin': 837,\n",
              " 'bob': 838,\n",
              " 'stash': 839,\n",
              " 'powdered': 840,\n",
              " 'amish': 841,\n",
              " 'winter': 842,\n",
              " 'cafe': 843,\n",
              " 'going': 844,\n",
              " 'sucralose': 845,\n",
              " 'panda': 846,\n",
              " 'selection': 847,\n",
              " 'before': 848,\n",
              " 'sardines': 849,\n",
              " 'windows': 850,\n",
              " 'mic': 851,\n",
              " 'five': 852,\n",
              " 'needed': 853,\n",
              " 'solid': 854,\n",
              " 'thank': 855,\n",
              " 'biscuits': 856,\n",
              " 'cuppa': 857,\n",
              " 'messy': 858,\n",
              " 'nutritious': 859,\n",
              " 'jar': 860,\n",
              " 'skittles': 861,\n",
              " 'hawaiian': 862,\n",
              " 'defective': 863,\n",
              " 'sumatra': 864,\n",
              " 'paris': 865,\n",
              " 'taffy': 866,\n",
              " 'twizzlers': 867,\n",
              " 'convenience': 868,\n",
              " 'next': 869,\n",
              " 'pay': 870,\n",
              " 'creamer': 871,\n",
              " 'apple': 872,\n",
              " 'everyday': 873,\n",
              " 'allergic': 874,\n",
              " 'kick': 875,\n",
              " 'rip': 876,\n",
              " 'fluffy': 877,\n",
              " 'office': 878,\n",
              " 'nearly': 879,\n",
              " 'quantity': 880,\n",
              " 'such': 881,\n",
              " 'kcups': 882,\n",
              " 'shot': 883,\n",
              " 'saves': 884,\n",
              " 'lol': 885,\n",
              " 'doesn': 886,\n",
              " 'pearl': 887,\n",
              " 'belgian': 888,\n",
              " 'yourself': 889,\n",
              " 'mountain': 890,\n",
              " 'mostly': 891,\n",
              " 'large': 892,\n",
              " 'egg': 893,\n",
              " 'take': 894,\n",
              " 'perfection': 895,\n",
              " 'tang': 896,\n",
              " 'caution': 897,\n",
              " 'stock': 898,\n",
              " 'sometimes': 899,\n",
              " 'plocky': 900,\n",
              " 'stop': 901,\n",
              " 'nom': 902,\n",
              " 'side': 903,\n",
              " 'meat': 904,\n",
              " 'anything': 905,\n",
              " 'funny': 906,\n",
              " 'subscription': 907,\n",
              " 'constipation': 908,\n",
              " 'online': 909,\n",
              " 'truffle': 910,\n",
              " 'mueslix': 911,\n",
              " 'grocery': 912,\n",
              " 'somewhat': 913,\n",
              " 'lives': 914,\n",
              " 'tiny': 915,\n",
              " 'dried': 916,\n",
              " 'gummy': 917,\n",
              " 'bears': 918,\n",
              " 'advertising': 919,\n",
              " 'lollipops': 920,\n",
              " 'cinnamon': 921,\n",
              " 'potatoes': 922,\n",
              " 'power': 923,\n",
              " 'cakes': 924,\n",
              " 'classic': 925,\n",
              " 'rule': 926,\n",
              " 'liver': 927,\n",
              " 'sweetness': 928,\n",
              " 'mixes': 929,\n",
              " 'bone': 930,\n",
              " 'shop': 931,\n",
              " 'noodles': 932,\n",
              " 'strength': 933,\n",
              " 'cook': 934,\n",
              " 'choc': 935,\n",
              " 'body': 936,\n",
              " 'packed': 937,\n",
              " 'snacking': 938,\n",
              " 'wonderfully': 939,\n",
              " 'stephen': 940,\n",
              " 'short': 941,\n",
              " 'someone': 942,\n",
              " 'while': 943,\n",
              " 'strange': 944,\n",
              " 'concept': 945,\n",
              " 'pod': 946,\n",
              " 'inside': 947,\n",
              " 'martini': 948,\n",
              " 'condiment': 949,\n",
              " 'stonewall': 950,\n",
              " 'christmas': 951,\n",
              " 'holiday': 952,\n",
              " 'especially': 953,\n",
              " 'month': 954,\n",
              " 'oily': 955,\n",
              " 'truly': 956,\n",
              " 'put': 957,\n",
              " 'chew': 958,\n",
              " 'pricy': 959,\n",
              " 'diabetic': 960,\n",
              " 'chewy': 961,\n",
              " 'wake': 962,\n",
              " 'absolute': 963,\n",
              " 'package': 964,\n",
              " 'poorly': 965,\n",
              " 'rose': 966,\n",
              " 'ugh': 967,\n",
              " 'seed': 968,\n",
              " 'affordable': 969,\n",
              " 'bother': 970,\n",
              " 'part': 971,\n",
              " 'news': 972,\n",
              " 'usa': 973,\n",
              " 'vita': 974,\n",
              " 'gross': 975,\n",
              " 'oreos': 976,\n",
              " 'kit': 977,\n",
              " 'set': 978,\n",
              " 'island': 979,\n",
              " 'hodgson': 980,\n",
              " 'starbucks': 981,\n",
              " 'drinkers': 982,\n",
              " 'description': 983,\n",
              " 'word': 984,\n",
              " 'nature': 985,\n",
              " 'blood': 986,\n",
              " 'stick': 987,\n",
              " 'stopped': 988,\n",
              " 'icicle': 989,\n",
              " 'said': 990,\n",
              " 'decaff': 991,\n",
              " 'bitterness': 992,\n",
              " 'careful': 993,\n",
              " 'wasa': 994,\n",
              " 'being': 995,\n",
              " 'paws': 996,\n",
              " 'colombian': 997,\n",
              " 'chews': 998,\n",
              " 'bones': 999,\n",
              " 'moldy': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFY9-1zVdiJ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_seq(input_seq):\n",
        "  state_values = encoder_model.predict(input_seq)\n",
        "  target_seq = np.zeros((1,1))\n",
        "  target_seq[0,0]=word2index_output['<start>']\n",
        "  eos=word2index_output['<end>']\n",
        "\n",
        "  output_sentence = []\n",
        "  for _ in range(10):\n",
        "    output_tokens,h,c= decoder_model.predict([target_seq]+state_values)\n",
        "    \n",
        "    idx = np.argmax(output_tokens[0,0,:])\n",
        "\n",
        "    if eos == idx:\n",
        "      break\n",
        "    word=''\n",
        "    if idx>0:\n",
        "      word = idx2word_sum[idx]\n",
        "      output_sentence.append(word)\n",
        "\n",
        "      target_seq[0,0]=idx\n",
        "      state_values = [h,c]\n",
        "    return ' '.join(output_sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOB4vVLzdiH2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 794
        },
        "outputId": "5262427a-dd93-4a27-fff7-520f841ddc57"
      },
      "source": [
        "while True:\n",
        "  i=np.random.choice(len(cleaned_text))\n",
        "    \n",
        "  input_seq=padded_input[i:i+1]\n",
        "  translation=decode_seq(input_seq)\n",
        "  print('-')\n",
        "  print('Input:',cleaned_text[i])\n",
        "  print('translation:',translation)\n",
        "    \n",
        "  ans=input('continue? [y/n]')\n",
        "  if ans and ans.lower().startswith('n'):\n",
        "      break"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input: best way buy Beer Nuts Perhaps product exposed high heat whole lot shaking Most coating flavoring nuts Even though individual cans sealed like nuts sitting bowl long time hot humid day\n",
            "translation: perfect\n",
            "continue? [y/n]y\n",
            "-\n",
            "Input: two four year old enjoy cookies Good tasting convenient packaging individually wrapped Great stuffing glove compartment emergencies right size kids bad stuff complaints\n",
            "translation: than\n",
            "continue? [y/n]y\n",
            "-\n",
            "Input: really excited try clam chowder Maine wow think Campbell might even better\n",
            "translation: perfect\n",
            "continue? [y/n]y\n",
            "-\n",
            "Input: This Crackers good They little calories little fat still crunchy creamy diet right really help craving moments Depending caving eat plain turkey spread kids friends love eat cream cheese makes healthy snack Buying Amazon great idea cost less fresher stores even store get\n",
            "translation: perfect\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-b82de5af266b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'translation:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtranslation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mans\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'continue? [y/n]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mans\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m         )\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYXv_WiPdiEk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i=np.random.randint(len(cleaned_text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Di3bEkq6ksjP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef6c6a0c-f761-4bb7-fdab-fca948f00843"
      },
      "source": [
        "i"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5781"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR! Session/line number was not unique in database. History logging moved to new session 63\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-THLwQkoxu1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}